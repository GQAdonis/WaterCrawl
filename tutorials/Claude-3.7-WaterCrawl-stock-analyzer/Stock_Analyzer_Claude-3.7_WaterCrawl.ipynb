{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# \ud83d\udcb9\ud83d\ude80 Building a Stock Analyzer with WaterCrawl \u00d7 Claude 3.7 \u00d7 E2B \u00d7 Tavily\n",
    "\n",
    "Welcome to this **step-by-step Jupyter Notebook** where you'll unleash powerful financial analysis using the latest AI & scraping tools:\n",
    "\n",
    "1. \ud83d\udd77\ufe0f **WaterCrawl** \u2013 Lightning-fast, customizable web crawling for up-to-date stock info\n",
    "2. \ud83e\udd16 **Claude 3.7** \u2013 Expert-level financial analysis and crisp, structured insights\n",
    "3. \ud83d\udcca **E2B Code Interpreter** \u2013 Instantly visualize your findings, in-code!\n",
    "4. \ud83d\udd0e **Tavily Search API** \u2013 Find just the right stock pages (so you're always using the freshest data!)\n",
    "\n",
    "---\n",
    "\n",
    "### What will you learn? \ud83d\udc68\u200d\ud83c\udf93\ud83d\udc69\u200d\ud83d\udcbb\n",
    "\n",
    "- How to set up WaterCrawl + API keys in minutes\n",
    "- \ud83d\udd78\ufe0f Crawl and extract financial data, zero HTML hassle\n",
    "- \ud83d\udcc8 Supercharge stock insights using Claude 3.7\n",
    "- \ud83d\udcca Generate pretty Python charts from your AI analysis\n",
    "- \ud83d\udca1 Pro tips for reliable, robust data scraping and analytics\n",
    "\n",
    "---\n",
    "\n",
    "#### \ud83d\udd11 **What do you need?**\n",
    "\n",
    "| Service       | Key Purpose                | Where to generate                               |\n",
    "|--------------|---------------------------|-------------------------------------------------|\n",
    "| WaterCrawl   | Crawl anything            | [Get API key](https://app.watercrawl.dev/dashboard/api-keys)     |\n",
    "| Anthropic    | Power Claude 3.7          | [Get API key](https://console.anthropic.com/settings/keys)       |\n",
    "| E2B          | In-notebook code & plots  | [Get API key](https://app.e2b.dev/)             |\n",
    "| Tavily Search| Find relevant URLs fast   | [Get API key](https://app.tavily.com/home)      |\n",
    "\n",
    "Let's begin! \ud83c\udf89"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## 1. \ud83d\udea6 Setup and Installation\n",
    "\n",
    "> **Install all dependencies in one go!**"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install watercrawl-py anthropic e2b-code-interpreter python-dotenv matplotlib requests"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## 2. \ud83d\udce6 Import Required Libraries\n",
    "\n",
    "> Bring in the packages you'll use for everything from crawling to charting."
   ]
  },
  {
   "cell_type": "code",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from watercrawl import WaterCrawlAPIClient\n",
    "import anthropic\n",
    "from e2b_code_interpreter import Sandbox\n",
    "import base64\n",
    "import json\n",
    "from dotenv import load_dotenv\n",
    "import matplotlib.pyplot as plt\n",
    "from IPython.display import Image, display\n",
    "import requests"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## 3. \ud83d\udd11 Load Environment Variables\n",
    "\n",
    "> **Never hardcode your API keys!** Store them safely in a `.env` file for peace of mind \ud83d\udcbc\ud83d\udd12\n",
    "\n",
    "A sample `.env` should look like:\n",
    "```env\n",
    "WATERCRAWL_API_KEY=sk-... \n",
    "ANTHROPIC_API_KEY=sk-ant-... \n",
    "E2B_API_KEY=pk-e2b-... \n",
    "TAVILY_API_KEY=sk-tavily-... \n",
    "```\n"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load environment variables from .env\n",
    "load_dotenv()\n",
    "\n",
    "# Retrieve API keys\n",
    "watercrawl_api_key = os.getenv(\"WATERCRAWL_API_KEY\")\n",
    "anthropic_api_key = os.getenv(\"ANTHROPIC_API_KEY\")\n",
    "e2b_api_key = os.getenv(\"E2B_API_KEY\")\n",
    "tavily_api_key = os.getenv(\"TAVILY_API_KEY\")\n",
    "\n",
    "# Initialize clients\n",
    "watercrawl_client = WaterCrawlAPIClient(api_key=watercrawl_api_key)\n",
    "claude_client = anthropic.Anthropic(api_key=anthropic_api_key)\n",
    "sandbox = Sandbox(api_key=e2b_api_key)\n",
    "\n",
    "print(\"\u2705 All clients initialized!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## 4. \ud83d\udee0\ufe0f Define Helper Functions\n",
    "\n",
    "> These functions stitch together the search, crawl, and analysis magic! \ud83e\ude84"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_relevant_stock_pages(stock_symbol, base_url):\n",
    "    \"\"\"\n",
    "    \ud83d\udd0e Find relevant stock pages using Tavily Search API\n",
    "    \"\"\"\n",
    "    print(f\"Searching for \ud83d\udcc8 stock: {stock_symbol} on {base_url}\")\n",
    "    try:\n",
    "        url = \"https://api.tavily.com/search\"\n",
    "        payload = {\n",
    "            \"query\": f\"{stock_symbol} stock analysis site:{base_url}\",\n",
    "            \"topic\": \"finance\",\n",
    "            \"search_depth\": \"basic\",\n",
    "            \"max_results\": 5,\n",
    "            \"include_domains\": [base_url],\n",
    "            \"include_answer\": False\n",
    "        }\n",
    "        headers = {\n",
    "            \"Authorization\": f\"Bearer {tavily_api_key}\",\n",
    "            \"Content-Type\": \"application/json\"\n",
    "        }\n",
    "        response = requests.post(url, json=payload, headers=headers)\n",
    "        response.raise_for_status()\n",
    "        results = response.json()\n",
    "        urls = [item.get(\"url\") for item in results.get(\"results\", []) if item.get(\"url\")]\n",
    "        print(f\"\ud83d\udd17 Found {len(urls)} relevant pages!\")\n",
    "        return urls\n",
    "    except Exception as e:\n",
    "        print(f\"\u26a0\ufe0f Error finding stock pages: {str(e)}\")\n",
    "        return []"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {},
   "outputs": [],
   "source": [
    "def analyze_stock_data(stock_pages, client):\n",
    "    \"\"\"\n",
    "    \ud83e\udd16 Analyze stock data using Claude 3.7\n",
    "    \"\"\"\n",
    "    if not stock_pages:\n",
    "        print(\"\u274c No pages provided for analysis!\")\n",
    "        return None\n",
    "    try:\n",
    "        stock_contents = []\n",
    "        for page_url in stock_pages[:5]:  # Only the top 5\n",
    "            try:\n",
    "                scrape_result = watercrawl_client.scrape_url(\n",
    "                    url=page_url,\n",
    "                    page_options={\n",
    "                        \"exclude_tags\": [\"nav\", \"footer\"],\n",
    "                        \"include_tags\": [\"article\", \"main\"],\n",
    "                        \"wait_time\": 1500,\n",
    "                        \"include_html\": False,\n",
    "                        \"only_main_content\": True\n",
    "                    }\n",
    "                )\n",
    "                stock_contents.append({\n",
    "                    'url': page_url,\n",
    "                    'content': scrape_result.get('content', '')\n",
    "                })\n",
    "            except Exception as e:\n",
    "                print(f\"\u26a0\ufe0f Error scraping {page_url}: {str(e)}\")\n",
    "        \n",
    "        if not stock_contents:\n",
    "            print(\"\ud83d\ude22 No content scraped from pages!\")\n",
    "            return None\n",
    "        \n",
    "        analyze_prompt = \"\"\"\n",
    "You are a financial analyst. Based on the following stock information, analyze and provide in JSON:\n",
    "- company_overview\n",
    "- financial_health\n",
    "- growth_potential\n",
    "- risk_factors\n",
    "- investment_score (0-100)\n",
    "\n",
    "Stock Information:\n",
    "\"\"\"\n",
    "        for stock in stock_contents:\n",
    "            analyze_prompt += f\"\\nURL: {stock['url']}\\nContent: {stock['content']}\\n\"\n",
    "        \n",
    "        # Claude 3.7 call\n",
    "        completion = client.messages.create(\n",
    "            model=\"claude-3-7-sonnet-20250219\",\n",
    "            max_tokens=1000,\n",
    "            temperature=0,\n",
    "            system=\"You are a financial analyst. Provide detailed, accurate analysis in valid JSON format.\",\n",
    "            messages=[{\"role\": \"user\", \"content\": analyze_prompt}]\n",
    "        )\n",
    "        response_text = completion.content[0].text\n",
    "\n",
    "        try:\n",
    "            json_start = response_text.find('{')\n",
    "            json_end = response_text.rfind('}') + 1\n",
    "            if json_start != -1 and json_end != 0:\n",
    "                json_str = response_text[json_start:json_end]\n",
    "                return json.loads(json_str)\n",
    "            else:\n",
    "                print('\u26a0\ufe0f Claude did not return valid JSON. Output:')\n",
    "                print(response_text)\n",
    "                return None\n",
    "        except json.JSONDecodeError as e:\n",
    "            print(f'\u26a0\ufe0f JSON parsing error: {str(e)}')\n",
    "            print('Full response:', response_text)\n",
    "            return None\n",
    "    except Exception as e:\n",
    "        print(f'\u26a0\ufe0f Error analyzing stock data: {str(e)}')\n",
    "        return None"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {},
   "outputs": [],
   "source": [
    "def visualize_analysis(analysis_result):\n",
    "    \"\"\"\n",
    "    \ud83d\udcca Visualize the stock analysis results with a beautiful chart!\n",
    "    \"\"\"\n",
    "    try:\n",
    "        plt.figure(figsize=(8, 5))\n",
    "        plt.bar(['Investment Score'], [analysis_result['investment_score']], color='skyblue')\n",
    "        plt.ylim(0, 100)\n",
    "        plt.title('\ud83d\udcc8 Stock Investment Analysis Score')\n",
    "        plt.ylabel('Score (higher = better)')\n",
    "        plt.tight_layout()\n",
    "        plt.savefig('stock_analysis.png')\n",
    "        plt.close()\n",
    "        # Show inline in notebook\n",
    "        display(Image('stock_analysis.png'))\n",
    "        print(\"\\n\ud83d\udd0d **Detailed Insights**\")\n",
    "        print(f\"- **Company Overview**: {analysis_result['company_overview']}\")\n",
    "        print(f\"- **Financial Health**: {analysis_result['financial_health']}\")\n",
    "        print(f\"- **Growth Potential**: {analysis_result['growth_potential']}\")\n",
    "        print(f\"- **Risk Factors**: {analysis_result['risk_factors']}\")\n",
    "        print(f\"- **Investment Score**: {analysis_result['investment_score']}/100\")\n",
    "    except Exception as e:\n",
    "        print(f'\u26a0\ufe0f Visualization error: {str(e)}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## 5. \ud83c\udfc1 Main Analysis Function\n",
    "\n",
    "> The \"easy button\" for stock analysis: runs search, scrape, AI, and chart in one call!"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {},
   "outputs": [],
   "source": [
    "def analyze_stock(stock_symbol):\n",
    "    \"\"\"\n",
    "    \ud83c\udfe2\ud83d\udd0d Analyze any stock and visualize the result!\n",
    "    \"\"\"\n",
    "    base_url = \"https://finance.yahoo.com\"  # Trusted finance portal\n",
    "    print(f'\\n=== \ud83c\udfe6 Starting analysis for: {stock_symbol} ===')\n",
    "    stock_pages = find_relevant_stock_pages(stock_symbol, base_url)\n",
    "    if not stock_pages:\n",
    "        print('\u274c Could not find relevant stock pages')\n",
    "        return\n",
    "    analysis_result = analyze_stock_data(stock_pages, claude_client)\n",
    "    if analysis_result:\n",
    "        visualize_analysis(analysis_result)\n",
    "    else:\n",
    "        print('\u274c Failed to analyze stock data.')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## 6. \ud83c\udfac Run the Analysis!\n",
    "\n",
    "Ready to test? Just type a ticker (e.g. `AAPL`, `TSLA`, `GOOG`, `NFLX`) and watch the pipeline go! \ud83d\udea6"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {},
   "outputs": [],
   "source": [
    "analyze_stock('AAPL')   # \ud83c\udf4f Feel free to try other symbols here!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## 7. \ud83d\udca1 Best Practices & Tips\n",
    "\n",
    "\u2714\ufe0f **Rate Limiting**: WaterCrawl is smart, but don't hammer sites! Consider sleep delays for big scrapes.\n",
    "\n",
    "\u2714\ufe0f **Error Handling**: Always check responses, catch exceptions, and log unexpected content.\n",
    "\n",
    "\u2714\ufe0f **Data Quality**: Validate what you scrape, and if investing, always double-check data from multiple sources.\n",
    "\n",
    "\u2714\ufe0f **Performance**: For mass crawling, consider async techniques or chunked batches.\n",
    "\n",
    "_**Note:** This demo is for educational purposes. Do not use AI output as investment advice!_\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## 8. \ud83c\udf31 Next Steps & Remix Ideas\n",
    "\n",
    "\ud83c\udfaf Try analyzing more tickers or sectors\n",
    "\n",
    "\ud83d\udcc5 Add historical trends & time series charts\n",
    "\n",
    "\ud83d\udd04 Incorporate technical indicators\n",
    "\n",
    "\ud83d\udd25 Build a portfolio analyzer by looping over a stock list\n",
    "\n",
    "_Happy Crawling & Analyzing!_\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}